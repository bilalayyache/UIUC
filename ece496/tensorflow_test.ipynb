{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from scipy import signal\n",
    "from imageio import imread\n",
    "from random import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_images\n",
    "    # Read in images and makes a list for each set in the form: [images, labels]\n",
    "    # images: np array with dims [N x img_height x img width x num_channels]\n",
    "    # labels: np array with dims [N x 1]. elephant = 0, lionfish = 1\n",
    "    #\n",
    "    # Returns:  train_set: The list [train_images, train_labels]\n",
    "    #           val_set: The list [val_images, val_labels] \n",
    "\n",
    "def load_images():\n",
    "    \n",
    "    sets = ['train', 'val']\n",
    "    \n",
    "    data_sets = []\n",
    "    for dset in sets:\n",
    "        img_path = './bin_dataset/' + dset + '/ele'\n",
    "        ele_list = [imread(os.path.join(img_path, img)) for img in os.listdir(img_path)]\n",
    "\n",
    "        img_path = './bin_dataset/' + dset + '/lio'\n",
    "        lio_list = [imread(os.path.join(img_path, img)) for img in os.listdir(img_path)]\n",
    "\n",
    "        set_images = np.stack(ele_list + lio_list)\n",
    "        N = set_images.shape[0]\n",
    "        labels = np.ones((N,1))\n",
    "        labels[0:int(N/2)] = 0\n",
    "        data_sets.append([set_images, labels])\n",
    "\n",
    "    train_set, val_set = data_sets\n",
    "\n",
    "    print(\"Loaded\", len(train_set[0]), \"training images\")\n",
    "    print(\"Loaded\", len(val_set[0]), \"validation images\")\n",
    "    \n",
    "    return train_set, val_set\n",
    "\n",
    "\n",
    "# batchify\n",
    "    # Inputs:    train_set: List containing images and labels\n",
    "    #            batch size: The desired size of each batch\n",
    "    #\n",
    "    # Returns:   image_batches: A list of shuffled training image batches, each with size batch_size\n",
    "    #            label_batches: A list of shuffled training label batches, each with size batch_size \n",
    "\n",
    "def batchify(train_set, batch_size):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # initialized two lists\n",
    "    image_batches = []\n",
    "    label_batches = []\n",
    "    \n",
    "    shuffle_index = np.arange(len(train_set[0]))\n",
    "    shuffle(shuffle_index)\n",
    "    \n",
    "    image_chunk = [None] * batch_size\n",
    "    label_chunk = [None] * batch_size\n",
    "    for c in range(0, len(shuffle_index), batch_size):\n",
    "        for i in range(batch_size):\n",
    "            image_chunk[i] = train_set[0][shuffle_index[c+i]]\n",
    "            label_chunk[i] = train_set[1][shuffle_index[c+i]]\n",
    "        image_batches.append(np.array(image_chunk))\n",
    "        label_batches.append(np.array(label_chunk))\n",
    "\n",
    "    return image_batches, label_batches\n",
    "\n",
    "def data_transform(data_set):\n",
    "    data, label = data_set\n",
    "    data = data.astype(float)\n",
    "    data /= 256.0\n",
    "    return [data, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and scale them\n",
    "# YOUR CODE HERE\n",
    "train_set, val_set = load_images()\n",
    "train_set = data_transform(train_set)\n",
    "val_set = data_transform(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_2:0\", shape=(4,), dtype=int32) Tensor(\"Const_3:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"Mul_1:0\", shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Initialize two constants\n",
    "x1 = tf.constant([1,2,3,4])\n",
    "x2 = tf.constant([5,6,7,8])\n",
    "print(x1, x2)\n",
    "# Multiply\n",
    "result = tf.multiply(x1, x2)\n",
    "\n",
    "# Print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 20\n",
    "lr = 0.1\n",
    "image_size = 100\n",
    "batch_size = 16\n",
    "filter_len = 5\n",
    "num_out_ch = 3\n",
    "mp_len = 12\n",
    "fc_nodes = 2\n",
    "W1_len = int((image_size-filter_len+1)/mp_len)\n",
    "decay = 0.8\n",
    "# Declare weights\n",
    "# YOUR CODE HERE\n",
    "# W0 = np.random.normal(0, 0.05, weights['W0'].shape)\n",
    "# W1 = np.random.normal(0, 0.05, weights['W1'].shape)\n",
    "# W2 = np.random.normal(0, 0.05, weights['W2'].shape)\n",
    "# print(W0.shape)\n",
    "# print(W1.shape)\n",
    "# print(W2.shape)\n",
    "W0 = np.random.normal(0, 0.05, (num_out_ch, filter_len, filter_len, 3))\n",
    "W1 = np.random.normal(0, 0.05, (W1_len*W1_len*num_out_ch, fc_nodes))\n",
    "W2 = np.random.normal(0, 0.05, (fc_nodes, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(3, 5, 5, 3), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "i = tf.reshape(W0, [-1, 5, 5, 3])\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'W0_8:0' shape=(3, 5, 5, 3) dtype=float64_ref> <tf.Variable 'W1_2:0' shape=(192, 2) dtype=float64_ref> <tf.Variable 'W2_2:0' shape=(2, 1) dtype=float64_ref>\n"
     ]
    }
   ],
   "source": [
    "W0 = tf.Variable(W0, name='W0')\n",
    "W1 = tf.Variable(W1, name='W1')\n",
    "W2 = tf.Variable(W2, name='W2')\n",
    "print(W0, W1, W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(N, input_image, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # Input Layer\n",
    "    input_layer = tf.reshape(input_image, [N, 100, 100, 3])\n",
    "    \n",
    "    # Convolutional Layer #1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=3,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"valid\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=12, strides=12)\n",
    "\n",
    "    pool1_flat = tf.reshape(pool1, [N, -1])\n",
    "\n",
    "    # Dense Layer\n",
    "    dense1 = tf.layers.dense(inputs=pool1_flat, units=5, activation=tf.nn.relu)\n",
    "    \n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=dense1, units=2)\n",
    "\n",
    "    predictions = {\n",
    "        # Generate predictions (for PREDICT and EVAL mode)\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "        # `logging_hook`.\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "    \n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(\n",
    "            labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
