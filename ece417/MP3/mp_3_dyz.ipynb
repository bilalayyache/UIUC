{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Problem 3: NumPy CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from scipy import signal\n",
    "from imageio import imread\n",
    "from random import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_images\n",
    "    # Read in images and makes a list for each set in the form: [images, labels]\n",
    "    # images: np array with dims [N x img_height x img width x num_channels]\n",
    "    # labels: np array with dims [N x 1]. elephant = 0, lionfish = 1\n",
    "    #\n",
    "    # Returns:  train_set: The list [train_images, train_labels]\n",
    "    #           val_set: The list [val_images, val_labels] \n",
    "\n",
    "def load_images():\n",
    "    \n",
    "    sets = ['train', 'val']\n",
    "    \n",
    "    data_sets = []\n",
    "    for dset in sets:\n",
    "        img_path = './bin_dataset/' + dset + '/ele'\n",
    "        ele_list = [imread(os.path.join(img_path, img)) for img in os.listdir(img_path)]\n",
    "\n",
    "        img_path = './bin_dataset/' + dset + '/lio'\n",
    "        lio_list = [imread(os.path.join(img_path, img)) for img in os.listdir(img_path)]\n",
    "\n",
    "        set_images = np.stack(ele_list + lio_list)\n",
    "        N = set_images.shape[0]\n",
    "        labels = np.ones((N,1))\n",
    "        labels[0:int(N/2)] = 0\n",
    "        data_sets.append([set_images, labels])\n",
    "\n",
    "    train_set, val_set = data_sets\n",
    "\n",
    "    print(\"Loaded\", len(train_set[0]), \"training images\")\n",
    "    print(\"Loaded\", len(val_set[0]), \"validation images\")\n",
    "    \n",
    "    return train_set, val_set\n",
    "\n",
    "\n",
    "\n",
    "# batchify\n",
    "    # Inputs:    train_set: List containing images and labels\n",
    "    #            batch size: The desired size of each batch\n",
    "    #\n",
    "    # Returns:   image_batches: A list of shuffled training image batches, each with size batch_size\n",
    "    #            label_batches: A list of shuffled training label batches, each with size batch_size \n",
    "\n",
    "# def batchify(train_set, batch_size):   \n",
    "#     # YOUR CODE HERE\n",
    "#     indices = np.linspace(0, len(train_set[0])-1, num=len(train_set[0]), dtype=np.int16)\n",
    "#     shuffle(indices)\n",
    "#     image_batches = []\n",
    "#     label_batches = []\n",
    "#     b = 0;\n",
    "#     image_b = np.zeros((batch_size,len(train_set[0][0]),len(train_set[0][0][0]),len(train_set[0][0][0][0])))\n",
    "#     for i in range(0,int(len(train_set[0])/batch_size)):\n",
    "#         for x in range(0, len(train_set[0])):\n",
    "#             for b in range(0, batch_size):\n",
    "#                 image_b[b][:][:][:]=train_set[0][indices[x]]\n",
    "#                 label_batches[b]=train_set[1][indices[x]]              \n",
    "#         image_batches.append(np.array(image_b))\n",
    "#         label_batches.append(np.array(label_b)) \n",
    "#     return image_batches, label_batches\n",
    "def batchify(train_set, batch_size):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    indices = np.linspace(0, len(train_set[0])-1, num=len(train_set[0]), dtype=np.int16)\n",
    "    shuffle(indices)\n",
    "    image_batches = []\n",
    "    label_batches = []\n",
    "    b = 0;\n",
    "    image_b = []\n",
    "    label_b = []\n",
    "    for x in range(0, len(train_set[0])):\n",
    "        image_b.append(train_set[0][indices[x]])\n",
    "        label_b.append(train_set[1][indices[x]])\n",
    "        if(b == batch_size - 1):\n",
    "            image_batches.append(np.array(image_b))\n",
    "            label_batches.append(np.array(label_b))\n",
    "            b = 0\n",
    "            image_b = []\n",
    "            label_b = []\n",
    "        else:\n",
    "            b = b + 1\n",
    "    image_batches.append(np.array(image_b))\n",
    "    label_batches.append(np.array(label_b))  \n",
    "    return image_batches, label_batches\n",
    "def data_normalization(data_set):\n",
    "    data, label = data_set\n",
    "    data = data.astype(float)\n",
    "    data /= 256.0\n",
    "    return [data,label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train_set: 2 2000 100 100 3\n",
      "size of train_set: 2 2000 1\n"
     ]
    }
   ],
   "source": [
    "print('size of train_set:',len(train_set),len(train_set[0]),len(train_set[0][0]),len(train_set[0][0][0]),len(train_set[0][0][0][0]))\n",
    "print('size of train_set:',len(train_set),len(train_set[1]),len(train_set[1][0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relu\n",
    "    # Inputs:   x: Multi-dimensional array with size N along the first axis\n",
    "    # \n",
    "    # Returns:  out: Multi-dimensional array with same size of x \n",
    "\n",
    "def relu(x):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    out = np.maximum(0,x)\n",
    "    return out\n",
    "\n",
    "# sigmoid\n",
    "    # Inputs:    x: Multi-dimensional array with size N along the first axis\n",
    "    # \n",
    "    # Returns:   out: Multi-dimensional array with same size of x \n",
    "\n",
    "def sigmoid(x):\n",
    "    # YOUR CODE HERE\n",
    "    out = x\n",
    "    for i in range(0,len(x)):\n",
    "        out[i]=1/(1+np.exp(-x[i]));\n",
    "    return out\n",
    "\n",
    "\n",
    "# unit_step\n",
    "    # Inputs:    x: Multi-dimensional array with size N along the first axis \n",
    "    # \n",
    "    # Returns:   out: Multi-dimensional array with same size of x \n",
    "\n",
    "def unit_step(x):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    out=np.heaviside(x,1)\n",
    "    return out \n",
    "# temp= np.random.rand(5,5)-0.2\n",
    "# out=unit_step(temp)\n",
    "# print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3141319c4b94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mW1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mW2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mF0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvolve2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_set' is not defined"
     ]
    }
   ],
   "source": [
    "# convolve2D\n",
    "    # Inputs:    X: [N x height x width x num_channels]\n",
    "    #            filters: [num_filters x filter_height x filter_width x num_input_channels]\n",
    "    # \n",
    "    # Returns:   Xc: output array by convoling X and filters. [N x output_height x output_width x num_filters]\n",
    "\n",
    "def convolve2D(X0, filters):\n",
    "   \n",
    "    N, X0_len, _, num_ch = X0.shape\n",
    "    num_out_ch, filter_len, _, _ = filters.shape\n",
    "    F0_side = X0_len - filter_len + 1\n",
    "    F0 = np.zeros((N, F0_side, F0_side, num_out_ch))\n",
    "    \n",
    "    for n in range(N):\n",
    "        for o_ch in range(num_out_ch):\n",
    "            for ch in range(num_ch):\n",
    "#                 print(temp.shape)\n",
    "#                 print(F0[n][:,:,o_ch].shape)\n",
    "#                 print(X0[n][:,:,ch].shape)\n",
    "#                 print(filters[o_ch][:,:,ch].shape)\n",
    "                F0[n,0:,0:,o_ch] += signal.convolve2d(X0[n,0:,0:,ch], filters[o_ch,0:,0:,ch],mode='valid')\n",
    "                #print(F0[n][:][:][o_ch])\n",
    "    return F0\n",
    "# print((W0[0][:][:][0]))\n",
    "# print(W0)\n",
    "weights = np.load('weights.npz')\n",
    "W0 = weights['W0']\n",
    "W1 = weights['W1']\n",
    "W2 = weights['W2']\n",
    "F0=convolve2D(val_set[0], W0)\n",
    "print(len(F0),len(F0[0]),len(F0[0][0]))\n",
    "print(F0[0])\n",
    "\n",
    "# maxPool\n",
    "    # Inputs:    R0: [N x height x width x num_channels]\n",
    "    #            mp_len: size of max pool window, also the stride for this MP\n",
    "    # \n",
    "    # Returns:   p_out: output of pooling R0. [N x output_height x output_width x num_channels]\n",
    "    #            R0_mask: A binary mask with the same size as R0. Indicates which index was chosen to be the max\n",
    "    #            for each max pool window. This will be used for backpropagation.\n",
    "\n",
    "def maxPool(R0, mp_len):\n",
    "\n",
    "    N, R0_len, _, num_ch = R0.shape\n",
    "    p_out_len = int((R0_len-mp_len)/mp_len + 1)\n",
    "\n",
    "    R0_mask = np.zeros(R0.shape)\n",
    "    p_out = np.zeros((N, p_out_len, p_out_len, num_ch))\n",
    "    \n",
    "    for n in range(N):\n",
    "        for ch in range(num_ch):\n",
    "            for row in range(p_out_len): \n",
    "                for col in range(p_out_len):\n",
    "                    # YOUR CODE HERE\n",
    "                    max = 0;\n",
    "                    a_max = 0;\n",
    "                    b_max = 0;\n",
    "                    for a in range(mp_len*row,mp_len*(row+1)):\n",
    "                        for b in range(mp_len*col, mp_len*(col+1)):\n",
    "                            if (R0[n, a, b, ch] > max):\n",
    "                                max_ = R0[n, a, b, ch]\n",
    "                                a_max = a\n",
    "                                b_max = b\n",
    "                            if ((a == mp_len*(row+1) -1) and (b == mp_len*(col+1) -1)):\n",
    "                                R0_mask[n, a_max, b_max, ch]=1\n",
    "                                \n",
    "                    p_out[n, row, col, ch]=max_\n",
    "\n",
    "    return p_out, R0_mask\n",
    "# fc\n",
    "    # Inputs:    X: [N x num_input_features]\n",
    "    #            W: [num_input_features x num_fc_nodes]\n",
    "    # \n",
    "    # Returns:   out: Linear combination of X and W. [N x num_fc_nodes]\n",
    "\n",
    "def fc(X, W):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    out = np.matmul(X, W)\n",
    "    print(X.shape,W.shape)\n",
    "    return out\n",
    "\n",
    "# flatten\n",
    "    # Inputs:    X1: [N x output_height x output_width x num_channels]\n",
    "    # Return:    f_out: [N x (output_height x output_width x num_channels)]\n",
    "def flatten(X1):\n",
    "    N, num_rows, num_cols, num_ch = X1.shape\n",
    "    f_out = np.zeros((N, (num_rows * num_cols * num_ch)))\n",
    "    for n in range(N):\n",
    "        f_out[n] = X1[n].flatten()\n",
    "    return f_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_fwd\n",
    "    # Inputs:    X0: batch of images. [N x img_height x img_width x num_channels]\n",
    "    #            W0, W1, W2: Parameters of the CNN\n",
    "    #            mp_len: the length of one side of the max pool window\n",
    "    # \n",
    "    # Returns:   sig: vector containing the output for each sample. [N x 1]\n",
    "    #            cache: a dict containing the relevant output layer calculations that will be\n",
    "    #            used in backpropagation\n",
    "    \n",
    "def cnn_fwd(X0, W0, W1, W2, mp_len):\n",
    "    \n",
    "    # F0 \n",
    "    # YOUR CODE HERE\n",
    "    F0 = convolve2D(X0, W0)\n",
    "    # X1p \n",
    "    # YOUR CODE HERE\n",
    "    R0 = relu(F0)\n",
    "    X1p,R0_mask = maxPool(R0, mp_len)\n",
    "    # X1 (flatten)\n",
    "    # YOUR CODE HERE\n",
    "    X1 = flatten(X1p)\n",
    "    # FC Layers\n",
    "    # YOUR CODE HERE\n",
    "    F1 = fc(X1, W1)\n",
    "    X2 = relu(F1)\n",
    "    F2 = fc(X2,W2)\n",
    "    sig = sigmoid(F2)\n",
    "    # Output\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Save outputs of functions for backward pass\n",
    "    cache = {\n",
    "        \"F0\":F0,\n",
    "        \"R0\":R0,\n",
    "        \"X1p\":X1p,\n",
    "        \"R0m\":R0_mask,\n",
    "        \"X1\":X1,\n",
    "        \"F1\":F1,\n",
    "        \"X2\":X2,\n",
    "        \"F2\":F2      \n",
    "    }\n",
    "    \n",
    "    return sig, cache\n",
    "\n",
    "\n",
    "# loss\n",
    "    # Inputs:    sig: vector containing the CNN output for each sample. [N x 1]\n",
    "    #            Y: vector containing the ground truth label for each sample. [N x 1]\n",
    "    # \n",
    "    # Returns:   L: Loss/error criterion for the model. \n",
    "\n",
    "def loss(sig, Y):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    N = len(sig)\n",
    "    L = 0.0\n",
    "    for i in range(N):\n",
    "        L += (-Y[i])*np.log(sig[i])-(1.0-Y[i])*np.log(1.0-sig[i])\n",
    "        #print(L,sig[i],Y[i])\n",
    "    L=L/N\n",
    "    return L\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backprop Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convolve2DBwd\n",
    "    # Inputs:    X0: batch of images. [N x height x width x num_channels]\n",
    "    #            dL_dF0: Gradient at the output of the conv layer. \n",
    "    # \n",
    "    # Returns:   dL_dW0. gradient of loss L wrt W0. Same size as W0\n",
    "\n",
    "def convolve2DBwd(X0, dL_dF0):\n",
    "    \n",
    "    N, X0_len, _, num_ch = X0.shape\n",
    "    _, dL_dF0_len, _, num_out_ch  = dL_dF0.shape\n",
    "    filter_len = X0_len - dL_dF0_len + 1\n",
    "    \n",
    "    dL_dW0 = np.zeros((num_out_ch, filter_len, filter_len, num_ch))\n",
    "    \n",
    "    for n in range(N):\n",
    "        for o_ch in range(num_out_ch):\n",
    "            for ch in range(num_ch):\n",
    "                # YOUR CODE HERE \n",
    "    \n",
    "    return dL_dW0\n",
    "\n",
    "\n",
    "# maxPoolBwd\n",
    "    # Inputs:    dL_dX1p: Gradient at the output of the MaxPool layer\n",
    "    #            R0_mask: A binary mask with the same size as R0. Defined in maxPool\n",
    "    #            mp_len: the length of one side of the max pool window\n",
    "    # \n",
    "    # Returns:   dL_dR0: Gradient at the output of ReLu\n",
    "    \n",
    "def maxPoolBwd(dL_dX1p, R0_mask,  mp_len):\n",
    "    \n",
    "    N, H, W, C = R0_mask.shape\n",
    "    N, dH, dW, C = dL_dX1p.shape\n",
    "    \n",
    "    dL_dR0 = np.zeros(R0_mask.shape)\n",
    "    \n",
    "    for n in range(N):\n",
    "        for ch in range(C):\n",
    "            for row in range(dH):\n",
    "                for col in range(dW):\n",
    "                    # YOUR CODE HERE\n",
    "                    \n",
    "    return dL_dR0\n",
    "\n",
    "\n",
    "# dL_dW2\n",
    "    # Inputs:    Y: vector containing the ground truth label for each sample. [N x 1]\n",
    "    #            cache: a dict containing the relevant output layer calculations \n",
    "    # \n",
    "    # Returns:   dL_dW2: Gradient of the Loss wrt W2\n",
    "    \n",
    "def dL_dW2(Y, cache):\n",
    "   \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return dL_dW2\n",
    "\n",
    "\n",
    "# dL_dW1\n",
    "    # Inputs:    Y: vector containing the ground truth label for each sample. [N x 1]\n",
    "    #            W2: Weight matrix for the second FC layer\n",
    "    #            cache: a dict containing the relevant output layer calculations \n",
    "    # \n",
    "    # Returns:   dL_dW1: Gradient of the Loss wrt W1\n",
    "    \n",
    "def dL_dW1(Y, W2, cache):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return dL_dW1\n",
    "\n",
    "\n",
    "# dL_dW0\n",
    "    # Inputs:    X0: batch of images. [N x height x width x num_channels]\n",
    "    #            Y: vector containing the ground truth label for each sample. [N x 1]\n",
    "    #            W1: Weight matrix for the first FC layer\n",
    "    #            W2: Weight matrix for the second FC layer\n",
    "    #            mp_len: the length of one side of the max pool window\n",
    "    #            cache: a dict containing the relevant output layer calculations \n",
    "    # \n",
    "    # Returns:   dL_dW0: Gradient of the Loss wrt W0\n",
    "\n",
    "def dL_dW0(X0, Y, W1, W2, mp_len, cache):\n",
    "    \n",
    "    N, X1p_len, _, no_out_ch  = cache['X1p'].shape\n",
    "    F2 = cache['F2']\n",
    "    F1 = cache['F1']\n",
    "    R0m = cache['R0m']\n",
    "    F0 = cache['F0']\n",
    "    \n",
    "    #dL_dF2\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    #dL_dF1\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    #dL_dX1\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # dL_dX1p (unflatten)\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # dL_dR0 (unpool)\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # dL_dF0 (relu_bwd)\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # dL_dW0\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return dL_dW0\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2000 training images\n",
      "Loaded 800 validation images\n",
      "[[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [218 236 248]\n",
      "  [ 98  83  76]\n",
      "  [ 98  74  72]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [143 129 162]\n",
      "  [122 103 123]\n",
      "  [ 72  59 102]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [155 133 119]\n",
      "  [ 86  67  86]\n",
      "  [124 102  81]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[144 136 115]\n",
      "  [115 102  96]\n",
      "  [162 145 127]\n",
      "  ...\n",
      "  [172 168 133]\n",
      "  [222 202 152]\n",
      "  [140 111  71]]\n",
      "\n",
      " [[129 119 107]\n",
      "  [200 175 134]\n",
      "  [215 196 163]\n",
      "  ...\n",
      "  [187 163 119]\n",
      "  [198 166 117]\n",
      "  [163 124  85]]\n",
      "\n",
      " [[239 219 192]\n",
      "  [236 212 174]\n",
      "  [178 153 113]\n",
      "  ...\n",
      "  [249 240 207]\n",
      "  [170 135 113]\n",
      "  [190 166 128]]]\n"
     ]
    }
   ],
   "source": [
    "# Load images and scale them\n",
    "# YOUR CODE HERE\n",
    "train_set, val_set= load_images()\n",
    "print(val_set[0][0])\n",
    "train_set=data_normalization(train_set)\n",
    "val_set =data_normalization(val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 20\n",
    "lr = 0.1\n",
    "batch_size = 16\n",
    "filter_len = 5\n",
    "num_out_ch = 3\n",
    "mp_len = 12\n",
    "fc_nodes = 2\n",
    "\n",
    "# Declare weights\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(epochs):\n",
    "    \n",
    "    # make set of batches\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    for b_idx in range(num_batches):\n",
    "        X = img_batches[b_idx]\n",
    "        Y = label_batches[b_idx]\n",
    "        \n",
    "        # Forward pass\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # Calculate gradients\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # Update gradients\n",
    "        # YOUR CODE HERE\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Correctness of Forward and Backward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 192) (192, 2)\n",
      "(800, 2) (2, 1)\n",
      "train_loss: [0.55778204] train_acc: 0.7625\n"
     ]
    }
   ],
   "source": [
    "weights = np.load('weights.npz')\n",
    "W0 = weights['W0']\n",
    "W1 = weights['W1']\n",
    "W2 = weights['W2']\n",
    "\n",
    "sig, cache = cnn_fwd(val_set[0], W0, W1, W2, mp_len)\n",
    "train_acc = len(np.where(np.round(sig) == val_set[1])[0])/len(val_set[1])\n",
    "\n",
    "print(\"train_loss:\", loss(sig, val_set[1]), \"train_acc:\", train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 800 100 100 3\n",
      "[[[0.1875     0.23046875 0.16796875]\n",
      "  [0.22265625 0.234375   0.25390625]\n",
      "  [0.41015625 0.39453125 0.3984375 ]\n",
      "  ...\n",
      "  [0.78125    0.84375    0.79296875]\n",
      "  [0.19140625 0.2578125  0.1953125 ]\n",
      "  [0.5234375  0.58984375 0.52734375]]\n",
      "\n",
      " [[0.3828125  0.48046875 0.328125  ]\n",
      "  [0.34765625 0.40234375 0.34375   ]\n",
      "  [0.40625    0.4375     0.39453125]\n",
      "  ...\n",
      "  [0.62890625 0.69921875 0.64453125]\n",
      "  [0.30859375 0.37890625 0.32421875]\n",
      "  [0.43359375 0.50390625 0.44921875]]\n",
      "\n",
      " [[0.140625   0.26953125 0.0859375 ]\n",
      "  [0.2421875  0.34765625 0.2265625 ]\n",
      "  [0.30078125 0.375      0.296875  ]\n",
      "  ...\n",
      "  [0.24609375 0.32421875 0.27734375]\n",
      "  [0.5        0.5859375  0.53515625]\n",
      "  [0.35546875 0.44140625 0.39453125]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.515625   0.68359375 0.50390625]\n",
      "  [0.421875   0.6171875  0.41015625]\n",
      "  [0.4140625  0.640625   0.40234375]\n",
      "  ...\n",
      "  [0.4765625  0.61328125 0.30078125]\n",
      "  [0.5234375  0.66015625 0.33203125]\n",
      "  [0.60546875 0.7421875  0.421875  ]]\n",
      "\n",
      " [[0.34765625 0.51953125 0.37890625]\n",
      "  [0.4453125  0.62109375 0.453125  ]\n",
      "  [0.484375   0.6640625  0.47265625]\n",
      "  ...\n",
      "  [0.44140625 0.57421875 0.27734375]\n",
      "  [0.58203125 0.7265625  0.421875  ]\n",
      "  [0.41796875 0.56640625 0.2734375 ]]\n",
      "\n",
      " [[0.328125   0.515625   0.359375  ]\n",
      "  [0.3515625  0.515625   0.3359375 ]\n",
      "  [0.46875    0.61328125 0.4140625 ]\n",
      "  ...\n",
      "  [0.37109375 0.4921875  0.2265625 ]\n",
      "  [0.5703125  0.7109375  0.4296875 ]\n",
      "  [0.49609375 0.65234375 0.3671875 ]]]\n",
      "train_loss: [0.55778204]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(val_set),len(val_set[0]), len(val_set[0][0]),len(val_set[0][0][0]),len(val_set[0][0][0][0]))\n",
    "#print(cache['F0'][0])\n",
    "print(val_set[0][0])\n",
    "print(\"train_loss:\", loss(sig, val_set[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make backprop testing batch\n",
    "X_bp = np.vstack([train_set[0][0:8,:,:,:], train_set[0][-9:-1,:,:,:]])\n",
    "Y_bp = np.vstack([train_set[1][0:8], train_set[1][-9:-1]])\n",
    "\n",
    "# Initialize weights to all ones\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Update weights once\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "print(\"W2 value:\", np.sum(W2))\n",
    "print(\"W1 value:\", np.sum(W1))\n",
    "print(\"W0 value:\", np.sum(W0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
