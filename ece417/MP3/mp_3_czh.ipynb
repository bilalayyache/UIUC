{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Problem 3: NumPy CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from scipy import signal\n",
    "from imageio import imread\n",
    "from random import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_images\n",
    "    # Read in images and makes a list for each set in the form: [images, labels]\n",
    "    # images: np array with dims [N x img_height x img width x num_channels]\n",
    "    # labels: np array with dims [N x 1]. elephant = 0, lionfish = 1\n",
    "    #\n",
    "    # Returns:  train_set: The list [train_images, train_labels]\n",
    "    #           val_set: The list [val_images, val_labels] \n",
    "\n",
    "def load_images():\n",
    "    \n",
    "    sets = ['train', 'val']\n",
    "    \n",
    "    data_sets = []\n",
    "    for dset in sets:\n",
    "        img_path = './bin_dataset/' + dset + '/ele'\n",
    "        ele_list = [imread(os.path.join(img_path, img)) for img in os.listdir(img_path)]\n",
    "\n",
    "        img_path = './bin_dataset/' + dset + '/lio'\n",
    "        lio_list = [imread(os.path.join(img_path, img)) for img in os.listdir(img_path)]\n",
    "\n",
    "        set_images = np.stack(ele_list + lio_list)\n",
    "        N = set_images.shape[0]\n",
    "        labels = np.ones((N,1))\n",
    "        labels[0:int(N/2)] = 0\n",
    "        data_sets.append([set_images, labels])\n",
    "\n",
    "    train_set, val_set = data_sets\n",
    "\n",
    "    print(\"Loaded\", len(train_set[0]), \"training images\")\n",
    "    print(\"Loaded\", len(val_set[0]), \"validation images\")\n",
    "    \n",
    "    return train_set, val_set\n",
    "\n",
    "\n",
    "# batchify\n",
    "    # Inputs:    train_set: List containing images and labels\n",
    "    #            batch size: The desired size of each batch\n",
    "    #\n",
    "    # Returns:   image_batches: A list of shuffled training image batches, each with size batch_size\n",
    "    #            label_batches: A list of shuffled training label batches, each with size batch_size \n",
    "\n",
    "def batchify(train_set, batch_size):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # initialized two lists\n",
    "    image_batches = []\n",
    "    label_batches = []\n",
    "    \n",
    "    shuffle_index = np.arange(len(train_set[0]))\n",
    "    shuffle(shuffle_index)\n",
    "    \n",
    "    image_chunk = [None] * batch_size\n",
    "    label_chunk = [None] * batch_size\n",
    "    for c in range(0, len(shuffle_index), batch_size):\n",
    "        for i in range(batch_size):\n",
    "            image_chunk[i] = train_set[0][shuffle_index[c+i]]\n",
    "            label_chunk[i] = train_set[1][shuffle_index[c+i]]\n",
    "        image_batches.append(image_chunk)\n",
    "        label_batches.append(label_chunk)\n",
    "    \n",
    "    return image_batches, label_batches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def data_transform(data_set):\n",
    "    data, label = data_set\n",
    "    data = data.astype(float)\n",
    "    data /= 256.0\n",
    "    return [data, label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relu\n",
    "    # Inputs:   x: Multi-dimensional array with size N along the first axis\n",
    "    # \n",
    "    # Returns:  out: Multi-dimensional array with same size of x \n",
    "\n",
    "def relu(x):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    out = np.maximum(x, 0)\n",
    "    return out\n",
    "\n",
    "\n",
    "# sigmoid\n",
    "    # Inputs:    x: Multi-dimensional array with size N along the first axis\n",
    "    # \n",
    "    # Returns:   out: Multi-dimensional array with same size of x \n",
    "\n",
    "def sigmoid(x):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    out = 1.0/(1 + np.exp(-x))\n",
    "    return out\n",
    "\n",
    "\n",
    "# unit_step\n",
    "    # Inputs:    x: Multi-dimensional array with size N along the first axis \n",
    "    # \n",
    "    # Returns:   out: Multi-dimensional array with same size of x \n",
    "\n",
    "def unit_step(x):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    out = np.heaviside(x, 1)\n",
    "    return out "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to calculate 2D convlolution\n",
    "# input X 2D array with size NxN\n",
    "# input F 2D array with size fxf\n",
    "# output out 2D array with size N+f-1 x N+f-1\n",
    "def convolution2D(X, F):\n",
    "    N, _ = X.shape\n",
    "    f, _ = F.shape\n",
    "    S = N-f+1\n",
    "    out = np.zeros((S, S))\n",
    "    for i in range(S):\n",
    "        for j in range(S):\n",
    "            out[i, j] = np.sum(F[::-1, ::-1]*X[i:i+f, j:j+f])\n",
    "    return out\n",
    "    \n",
    "# convolve2D\n",
    "    # Inputs:    X: [N x height x width x num_channels]\n",
    "    #            filters: [num_filters x filter_height x filter_width x num_input_channels]\n",
    "    # \n",
    "    # Returns:   Xc: output array by convoling X and filters. [N x output_height x output_width x num_filters]\n",
    "\n",
    "def convolve2D(X0, filters):\n",
    "   \n",
    "    N, X0_len, _, num_ch = X0.shape\n",
    "    num_out_ch, filter_len, _, _ = filters.shape\n",
    "    F0_side = X0_len - filter_len + 1\n",
    "    \n",
    "    F0 = np.zeros((N, F0_side, F0_side, num_out_ch))\n",
    "    \n",
    "    for n in range(N):\n",
    "        for o_ch in range(num_out_ch):\n",
    "            for ch in range(num_ch):\n",
    "                # YOUR CODE HERE\n",
    "                # F0[n, :, :, o_ch] += convolution2D(X0[n, :, :, ch], filters[o_ch, :, :, ch])\n",
    "                F0[n,0:,0:,o_ch] += signal.convolve2d(X0[n,0:,0:,ch], filters[o_ch, 0:, 0:, ch], mode = \"valid\")\n",
    "    return F0\n",
    "\n",
    "\n",
    "# maxPool\n",
    "    # Inputs:    R0: [N x height x width x num_channels]\n",
    "    #            mp_len: size of max pool window, also the stride for this MP\n",
    "    # \n",
    "    # Returns:   p_out: output of pooling R0. [N x output_height x output_width x num_channels]\n",
    "    #            R0_mask: A binary mask with the same size as R0. Indicates which index was chosen to be the max\n",
    "    #            for each max pool window. This will be used for backpropagation.\n",
    "\n",
    "def maxPool(R0, mp_len):\n",
    "\n",
    "    N, R0_len, _, num_ch = R0.shape\n",
    "    p_out_len = int((R0_len-mp_len)/mp_len + 1)\n",
    "\n",
    "    R0_mask = np.zeros(R0.shape)\n",
    "    p_out = np.zeros((N, p_out_len, p_out_len, num_ch))\n",
    "    \n",
    "    for n in range(N):\n",
    "        for ch in range(num_ch):\n",
    "            for row in range(p_out_len): \n",
    "                for col in range(p_out_len):\n",
    "                    # YOUR CODE HERE\n",
    "                    r = row*mp_len\n",
    "                    c = col*mp_len\n",
    "                    p_out[n, row, col, ch] = np.amax(R0[n, r:min(r+mp_len, R0_len), c:min(c+mp_len, R0_len), ch])\n",
    "                    max_idx = np.argmax(R0[n, r:min(r+mp_len, R0_len), c:min(c+mp_len, R0_len), ch])\n",
    "                    row_idx = max_idx // mp_len + r\n",
    "                    col_idx = max_idx % mp_len + c\n",
    "                    R0_mask[n][row_idx][col_idx][ch] = 1\n",
    "    return p_out, R0_mask\n",
    "\n",
    "def flatten(Y):\n",
    "    # flatten function takes a 4D array and output a 2D array\n",
    "    # input Y: N x N1 x N2 x K\n",
    "    # output out: N x (N1*N2*K)\n",
    "    N, N1, N2, K = Y.shape\n",
    "    out = Y.reshape((N, N1*N2*K))\n",
    "    return out\n",
    "\n",
    "# fc\n",
    "    # Inputs:    X: [N x num_input_features]\n",
    "    #            W: [num_input_features x num_fc_nodes]\n",
    "    # \n",
    "    # Returns:   out: Linear combination of X and W. [N x num_fc_nodes]\n",
    "\n",
    "def fc(X, W):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    out = X @ W\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[120. 156. 192.]\n",
      " [300. 336. 372.]\n",
      " [480. 516. 552.]]\n",
      "[[120 156 192]\n",
      " [300 336 372]\n",
      " [480 516 552]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(25).reshape((5, 5))\n",
    "b = np.arange(9).reshape((3, 3))\n",
    "C1 = convolution2D(a, b)\n",
    "C2 = signal.convolve2d(a, b, mode='valid')\n",
    "print(C1)\n",
    "print(C2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_fwd\n",
    "    # Inputs:    X0: batch of images. [N x img_height x img_width x num_channels]\n",
    "    #            W0, W1, W2: Parameters of the CNN\n",
    "    #            mp_len: the length of one side of the max pool window\n",
    "    # \n",
    "    # Returns:   sig: vector containing the output for each sample. [N x 1]\n",
    "    #            cache: a dict containing the relevant output layer calculations that will be\n",
    "    #            used in backpropagation\n",
    "    \n",
    "def cnn_fwd(X0, W0, W1, W2, mp_len):\n",
    "    \n",
    "    # F0 \n",
    "    # YOUR CODE HERE\n",
    "    F0 = convolve2D(X0, W0)\n",
    "    \n",
    "    # X1p \n",
    "    # YOUR CODE HERE\n",
    "    R0 = relu(F0)\n",
    "    X1p, R0_mask = maxPool(R0, mp_len)\n",
    "    \n",
    "    # X1 (flatten)\n",
    "    # YOUR CODE HERE\n",
    "    X1 = flatten(X1p)\n",
    "    \n",
    "    # FC Layers\n",
    "    # YOUR CODE HERE\n",
    "    F1 = fc(X1, W1)\n",
    "    \n",
    "    # Output\n",
    "    # YOUR CODE HERE\n",
    "    X2 = relu(F1)\n",
    "    F2 = fc(X2, W2)\n",
    "    sig = sigmoid(F2)\n",
    "    \n",
    "    # Save outputs of functions for backward pass\n",
    "    cache = {\n",
    "        \"F0\":F0,\n",
    "        \"R0\":R0,\n",
    "        \"X1p\":X1p,\n",
    "        \"R0m\":R0_mask,\n",
    "        \"X1\":X1,\n",
    "        \"F1\":F1,\n",
    "        \"X2\":X2,\n",
    "        \"F2\":F2      \n",
    "    }\n",
    "    \n",
    "    return sig, cache\n",
    "\n",
    "\n",
    "# loss\n",
    "    # Inputs:    sig: vector containing the CNN output for each sample. [N x 1]\n",
    "    #            Y: vector containing the ground truth label for each sample. [N x 1]\n",
    "    # \n",
    "    # Returns:   L: Loss/error criterion for the model. \n",
    "\n",
    "def loss(sig, Y):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # cross entropy\n",
    "    L = 0.0\n",
    "    N, _ = Y.shape\n",
    "    for i in range(N):\n",
    "        L -= Y[i]*np.log(sig[i]) + (1-Y[i])*np.log(1-sig[i])\n",
    "    L /= N\n",
    "    return L\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backprop Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convolve2DBwd\n",
    "#     # Inputs:    X0: batch of images. [N x height x width x num_channels]\n",
    "#     #            dL_dF0: Gradient at the output of the conv layer. \n",
    "#     # \n",
    "#     # Returns:   dL_dW0. gradient of loss L wrt W0. Same size as W0\n",
    "\n",
    "# def convolve2DBwd(X0, dL_dF0):\n",
    "    \n",
    "#     N, X0_len, _, num_ch = X0.shape\n",
    "#     _, dL_dF0_len, _, num_out_ch  = dL_dF0.shape\n",
    "#     filter_len = X0_len - dL_dF0_len + 1\n",
    "    \n",
    "#     dL_dW0 = np.zeros((num_out_ch, filter_len, filter_len, num_ch))\n",
    "    \n",
    "#     for n in range(N):\n",
    "#         for o_ch in range(num_out_ch):\n",
    "#             for ch in range(num_ch):\n",
    "#                 # YOUR CODE HERE \n",
    "    \n",
    "#     return dL_dW0\n",
    "\n",
    "\n",
    "# # maxPoolBwd\n",
    "#     # Inputs:    dL_dX1p: Gradient at the output of the MaxPool layer\n",
    "#     #            R0_mask: A binary mask with the same size as R0. Defined in maxPool\n",
    "#     #            mp_len: the length of one side of the max pool window\n",
    "#     # \n",
    "#     # Returns:   dL_dR0: Gradient at the output of ReLu\n",
    "    \n",
    "# def maxPoolBwd(dL_dX1p, R0_mask,  mp_len):\n",
    "    \n",
    "#     N, H, W, C = R0_mask.shape\n",
    "#     N, dH, dW, C = dL_dX1p.shape\n",
    "    \n",
    "#     dL_dR0 = np.zeros(R0_mask.shape)\n",
    "    \n",
    "#     for n in range(N):\n",
    "#         for ch in range(C):\n",
    "#             for row in range(dH):\n",
    "#                 for col in range(dW):\n",
    "#                     # YOUR CODE HERE\n",
    "                    \n",
    "#     return dL_dR0\n",
    "\n",
    "\n",
    "# # dL_dW2\n",
    "#     # Inputs:    Y: vector containing the ground truth label for each sample. [N x 1]\n",
    "#     #            cache: a dict containing the relevant output layer calculations \n",
    "#     # \n",
    "#     # Returns:   dL_dW2: Gradient of the Loss wrt W2\n",
    "    \n",
    "# def dL_dW2(Y, cache):\n",
    "   \n",
    "#     # YOUR CODE HERE\n",
    "    \n",
    "#     return dL_dW2\n",
    "\n",
    "\n",
    "# # dL_dW1\n",
    "#     # Inputs:    Y: vector containing the ground truth label for each sample. [N x 1]\n",
    "#     #            W2: Weight matrix for the second FC layer\n",
    "#     #            cache: a dict containing the relevant output layer calculations \n",
    "#     # \n",
    "#     # Returns:   dL_dW1: Gradient of the Loss wrt W1\n",
    "    \n",
    "# def dL_dW1(Y, W2, cache):\n",
    "    \n",
    "#     # YOUR CODE HERE\n",
    "    \n",
    "#     return dL_dW1\n",
    "\n",
    "\n",
    "# # dL_dW0\n",
    "#     # Inputs:    X0: batch of images. [N x height x width x num_channels]\n",
    "#     #            Y: vector containing the ground truth label for each sample. [N x 1]\n",
    "#     #            W1: Weight matrix for the first FC layer\n",
    "#     #            W2: Weight matrix for the second FC layer\n",
    "#     #            mp_len: the length of one side of the max pool window\n",
    "#     #            cache: a dict containing the relevant output layer calculations \n",
    "#     # \n",
    "#     # Returns:   dL_dW0: Gradient of the Loss wrt W0\n",
    "\n",
    "# def dL_dW0(X0, Y, W1, W2, mp_len, cache):\n",
    "    \n",
    "#     N, X1p_len, _, no_out_ch  = cache['X1p'].shape\n",
    "#     F2 = cache['F2']\n",
    "#     F1 = cache['F1']\n",
    "#     R0m = cache['R0m']\n",
    "#     F0 = cache['F0']\n",
    "    \n",
    "#     #dL_dF2\n",
    "#     # YOUR CODE HERE\n",
    "    \n",
    "#     #dL_dF1\n",
    "#     # YOUR CODE HERE\n",
    "    \n",
    "#     #dL_dX1\n",
    "#     # YOUR CODE HERE\n",
    "    \n",
    "#     # dL_dX1p (unflatten)\n",
    "#     # YOUR CODE HERE\n",
    "    \n",
    "#     # dL_dR0 (unpool)\n",
    "#     # YOUR CODE HERE\n",
    "    \n",
    "#     # dL_dF0 (relu_bwd)\n",
    "#     # YOUR CODE HERE\n",
    "    \n",
    "#     # dL_dW0\n",
    "#     # YOUR CODE HERE\n",
    "    \n",
    "#     return dL_dW0\n",
    "    \n",
    "        \n",
    "        \n",
    "####################################################################################################################\n",
    "\n",
    "# convolve2DBwd\n",
    "    # Inputs:    X0: batch of images. [N x height x width x num_channels]\n",
    "    #            dL_dF0: Gradient at the output of the conv layer. \n",
    "    # \n",
    "    # Returns:   dL_dW0. gradient of loss L wrt W0. Same size as W0\n",
    "\n",
    "def convolve2DBwd(X0, dL_dF0):\n",
    "    \n",
    "    N, X0_len, _, num_ch = X0.shape\n",
    "    _, dL_dF0_len, _, num_out_ch  = dL_dF0.shape\n",
    "    filter_len = X0_len - dL_dF0_len + 1\n",
    "    \n",
    "    dL_dW0 = np.zeros((num_out_ch, filter_len, filter_len, num_ch))\n",
    "    \n",
    "    for n in range(N):\n",
    "        for o_ch in range(num_out_ch):\n",
    "            for ch in range(num_ch):\n",
    "                # YOUR CODE HERE \n",
    "                dL_dW0 = 1 # edit code here\n",
    "    return dL_dW0\n",
    "\n",
    "# dL_dF2\n",
    "    # Inputs:    Y: vector containing the ground truth label for each sample. [N x 1]\n",
    "    #            cache: a dict containing the relevant output layer calculations \n",
    "    # \n",
    "    # Returns:   dL_dF2: Gradient of the Loss wrt F2\n",
    "def dL_dF2(Y, cache):\n",
    "    \n",
    "    sig = sigmoid(cache[\"F2\"])\n",
    "    N =  sig.shape[0]\n",
    "    dL_dF2 = np.subtract(sig - Y)/N\n",
    "    print(\"dL_dF2 should be 800x1, and get \", dL_dF2.shape)\n",
    "    \n",
    "    return dL_dF2\n",
    "\n",
    "# dL_dW2\n",
    "    # Inputs:    dL_dF2: Gradient of the Loss wrt F2\n",
    "    #            cache: a dict containing the relevant output layer calculations \n",
    "    #            W2: Weight matrix for the second FC layer\n",
    "    # \n",
    "    # Returns:   dL_dW2: Gradient of the Loss wrt W2\n",
    "    \n",
    "def dL_dW2(dL_dF2, cache, W2):\n",
    "   \n",
    "    # YOUR CODE HERE\n",
    "    X2 = cache[\"X2\"]\n",
    "    dL_dW2 = np.matmul(X2.T, dL_dF2)\n",
    "    dL_dX2 = np.matmul(W2.T, dL_dF2)\n",
    "    print(\"dL_dW2 should be 2x1, and get \", dL_dW2.shape)\n",
    "    print(\"dL_dX2 should be 800x1, and get \", dL_dX2.shape)\n",
    "    \n",
    "    return dL_dW2, dL_dX2\n",
    "\n",
    "# dL_dF1\n",
    "    # Inputs:    dL_dX2: Gradient of the Loss wrt X2\n",
    "    #            cache: a dict containing the relevant output layer calculations \n",
    "    # \n",
    "    # Returns:   dL_dF1: Gradient of the Loss wrt F1\n",
    "\n",
    "def dL_dF1(dL_dX2, cache):   \n",
    "    \n",
    "    F1 = cache[\"F1\"]\n",
    "    F1 = np.divide(F1, F1)\n",
    "    dL_dF1 = np.multiply(dL_dX2, F1)\n",
    "    print(\"dL_dF1 should be 800x1, and get \", dL_dF1.shape)\n",
    "    \n",
    "    return dL_dF1\n",
    "\n",
    "# dL_dW1\n",
    "    # Inputs:    dL_dF1: Gradient of the Loss wrt F1\n",
    "    #            W1: Weight matrix for the first FC layer\n",
    "    #            cache: a dict containing the relevant output layer calculations \n",
    "    # \n",
    "    # Returns:   dL_dW1: Gradient of the Loss wrt W1\n",
    "    \n",
    "def dL_dW1(dL_dF1, cache, W1):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    X1 = cache[\"X1\"]\n",
    "    dL_dW1 = np.matmul(X1.T, dL_dF1)\n",
    "    dL_dX1 = np.matmul(W1.T, dL_dF1)\n",
    "    print(\"dL_dW1 should be 192x2, and get \", dL_dW1.shape)\n",
    "    print(\"dL_dX1 should be 800x192, and get \", dL_dX1.shape)\n",
    "    \n",
    "    return dL_dW1, dL_dX1\n",
    "\n",
    "# dL_dX1p\n",
    "    # Inputs:    dL_dX1: Gradient of the Loss wrt X1\n",
    "    #\n",
    "    # Returns:   dL_dX1p: Gradient of the Loss wrt X1p\n",
    "    \n",
    "def dL_dX1p(dL_dX1):\n",
    "    \n",
    "    dL_dX1p = dL_dX1.reshape((dL_dX1.shape[0], 8, 8, 3)) \n",
    "    print(\"dL_dX1p should be 800x8x8x3, and get \", dL_dX1p.shape)\n",
    "    \n",
    "    return dL_dX1p\n",
    "\n",
    "# dL_dR0\n",
    "    # Inputs:    dL_dX1p: Gradient of the Loss wrt X1p\n",
    "    #            cache: a dict containing the relevant output layer calculations \n",
    "    #\n",
    "    # Returns:   dL_dR0: Gradient of the Loss wrt R0\n",
    "    \n",
    "def dL_dR0(dL_dX1p, cache):\n",
    "\n",
    "    R0m = cache['R0m']\n",
    "    dL_dR0 = R0m\n",
    "    for n in range(R0m.shape[0]):\n",
    "        for f in range(R0m.shape[-1]):\n",
    "            for r in range(R0m.shape[1]):\n",
    "                for c in range(R0m.shape[2]):\n",
    "                    dL_dR0[n][r][c][f] = R0m[n][r][c][f] * dL_dX1p[n][r//12][c//12][f]\n",
    "    print(\"dL_dR0 should be 800x96x96x3, and get \", dL_dR0.shape)\n",
    "    \n",
    "    return dL_dR0\n",
    "\n",
    "# dL_dF0\n",
    "    # Inputs:    dL_dR0: Gradient of the Loss wrt R0\n",
    "    #            cache: a dict containing the relevant output layer calculations \n",
    "    # \n",
    "    # Returns:   dL_dF0: Gradient of the Loss wrt F0\n",
    "\n",
    "def dL_dF0(dL_dR0, cache):   \n",
    "    \n",
    "    F0 = cache[\"F0\"]\n",
    "    F0 = np.divide(F0, F0)\n",
    "    dL_dF0 = np.multiply(dL_dR0, F0)\n",
    "    print(\"dL_dF0 should be 800x96x96x3, and get \", dL_dF0.shape)\n",
    "    \n",
    "    return dL_dF0\n",
    "    \n",
    "# dL_dW0\n",
    "    # Inputs:    X0: batch of images. [N x height x width x num_channels]\n",
    "    #            dL_dF0: Gradient of the Loss wrt F0\n",
    "    #            W0: Weight matrix for the convolutional layer\n",
    "    # \n",
    "    # Returns:   dL_dW0: Gradient of the Loss wrt W0\n",
    "\n",
    "def dL_dW0(X0, dL_dF0, W0):\n",
    "    \n",
    "    dL_dW0 = 1 # edit code here\n",
    "    \n",
    "    return dL_dW0\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2000 training images\n",
      "Loaded 800 validation images\n"
     ]
    }
   ],
   "source": [
    "# Load images and scale them\n",
    "# YOUR CODE HERE\n",
    "train_set, val_set = load_images()\n",
    "train_set = data_transform(train_set)\n",
    "val_set = data_transform(val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 20\n",
    "lr = 0.1\n",
    "batch_size = 16\n",
    "filter_len = 5\n",
    "num_out_ch = 3\n",
    "mp_len = 12\n",
    "fc_nodes = 2\n",
    "\n",
    "# Declare weights\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_batches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-e48c3b83d751>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mb_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_batches' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    \n",
    "    # make set of batches\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    for b_idx in range(num_batches):\n",
    "        X = img_batches[b_idx]\n",
    "        Y = label_batches[b_idx]\n",
    "        \n",
    "        # Forward pass\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # Calculate gradients\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # Update gradients\n",
    "        # YOUR CODE HERE\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Correctness of Forward and Backward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: [0.23266417] train_acc: 0.9175\n",
      "---total cost is 13.008033037185669 seconds ---\n"
     ]
    }
   ],
   "source": [
    "weights = np.load('weights.npz')\n",
    "W0 = weights['W0']\n",
    "W1 = weights['W1']\n",
    "W2 = weights['W2']\n",
    "\n",
    "# record the time for the execution\n",
    "start_time = time.time()\n",
    "sig, _ = cnn_fwd(val_set[0], W0, W1, W2, mp_len)\n",
    "train_acc = len(np.where(np.round(sig) == val_set[1])[0])/len(val_set[1])\n",
    "\n",
    "print(\"train_loss:\", loss(sig, val_set[1]), \"train_acc:\", train_acc)\n",
    "print(\"---total cost is %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make backprop testing batch\n",
    "X_bp = np.vstack([train_set[0][0:8,:,:,:], train_set[0][-9:-1,:,:,:]])\n",
    "Y_bp = np.vstack([train_set[1][0:8], train_set[1][-9:-1]])\n",
    "\n",
    "# Initialize weights to all ones\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Update weights once\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "print(\"W2 value:\", np.sum(W2))\n",
    "print(\"W1 value:\", np.sum(W1))\n",
    "print(\"W0 value:\", np.sum(W0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
