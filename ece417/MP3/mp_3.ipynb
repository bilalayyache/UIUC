{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Problem 3: NumPy CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from scipy import signal\n",
    "from imageio import imread\n",
    "from random import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_images\n",
    "    # Read in images and makes a list for each set in the form: [images, labels]\n",
    "    # images: np array with dims [N x img_height x img width x num_channels]\n",
    "    # labels: np array with dims [N x 1]. elephant = 0, lionfish = 1\n",
    "    #\n",
    "    # Returns:  train_set: The list [train_images, train_labels]\n",
    "    #           val_set: The list [val_images, val_labels] \n",
    "\n",
    "def load_images():\n",
    "    \n",
    "    sets = ['train', 'val']\n",
    "    \n",
    "    data_sets = []\n",
    "    for dset in sets:\n",
    "        img_path = './bin_dataset/' + dset + '/ele'\n",
    "        ele_list = [imread(os.path.join(img_path, img)) for img in os.listdir(img_path)]\n",
    "\n",
    "        img_path = './bin_dataset/' + dset + '/lio'\n",
    "        lio_list = [imread(os.path.join(img_path, img)) for img in os.listdir(img_path)]\n",
    "\n",
    "        set_images = np.stack(ele_list + lio_list)\n",
    "        N = set_images.shape[0]\n",
    "        labels = np.ones((N,1))\n",
    "        labels[0:int(N/2)] = 0\n",
    "        data_sets.append([set_images, labels])\n",
    "\n",
    "    train_set, val_set = data_sets\n",
    "\n",
    "    print(\"Loaded\", len(train_set[0]), \"training images\")\n",
    "    print(\"Loaded\", len(val_set[0]), \"validation images\")\n",
    "    \n",
    "    return train_set, val_set\n",
    "\n",
    "\n",
    "# batchify\n",
    "    # Inputs:    train_set: List containing images and labels\n",
    "    #            batch size: The desired size of each batch\n",
    "    #\n",
    "    # Returns:   image_batches: A list of shuffled training image batches, each with size batch_size\n",
    "    #            label_batches: A list of shuffled training label batches, each with size batch_size \n",
    "\n",
    "def batchify(train_set, batch_size):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # initialized two lists\n",
    "    image_batches = []\n",
    "    label_batches = []\n",
    "    \n",
    "    \n",
    "    return image_batches, label_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2000 training images\n",
      "Loaded 800 validation images\n"
     ]
    }
   ],
   "source": [
    "train_set, val_set = load_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_set[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relu\n",
    "    # Inputs:   x: Multi-dimensional array with size N along the first axis\n",
    "    # \n",
    "    # Returns:  out: Multi-dimensional array with same size of x \n",
    "\n",
    "def relu(x):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    out = np.maximum(x, 0)\n",
    "    return out\n",
    "\n",
    "\n",
    "# sigmoid\n",
    "    # Inputs:    x: Multi-dimensional array with size N along the first axis\n",
    "    # \n",
    "    # Returns:   out: Multi-dimensional array with same size of x \n",
    "\n",
    "def sigmoid(x):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    out = 1.0/(1 + np.exp(-x))\n",
    "    return out\n",
    "\n",
    "\n",
    "# unit_step\n",
    "    # Inputs:    x: Multi-dimensional array with size N along the first axis \n",
    "    # \n",
    "    # Returns:   out: Multi-dimensional array with same size of x \n",
    "\n",
    "def unit_step(x):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5 -4 -3 -2 -1]\n",
      " [ 0  1  2  3  4]]\n",
      "[[0.99330715 0.98201379 0.95257413 0.88079708 0.73105858]\n",
      " [0.5        0.26894142 0.11920292 0.04742587 0.01798621]]\n",
      "[[-5 -4 -3 -2 -1]\n",
      " [ 0  1  2  3  4]]\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(10).reshape((2, 5)) - 5\n",
    "print(x)\n",
    "y = sigmoid(x)\n",
    "print(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolve2D\n",
    "    # Inputs:    X: [N x height x width x num_channels]\n",
    "    #            filters: [num_filters x filter_height x filter_width x num_input_channels]\n",
    "    # \n",
    "    # Returns:   Xc: output array by convoling X and filters. [N x output_height x output_width x num_filters]\n",
    "\n",
    "def convolve2D(X0, filters):\n",
    "   \n",
    "    N, X0_len, _, num_ch = X0.shape\n",
    "    num_out_ch, filter_len, _, _ = filters.shape\n",
    "    F0_side = X0_len - filter_len + 1\n",
    "    \n",
    "    F0 = np.zeros((N, F0_side, F0_side, num_out_ch))\n",
    "    \n",
    "    for n in range(N):\n",
    "        for o_ch in range(num_out_ch):\n",
    "            for ch in range(num_ch):\n",
    "                # YOUR CODE HERE\n",
    "                \n",
    "    return F0\n",
    "\n",
    "\n",
    "# maxPool\n",
    "    # Inputs:    R0: [N x height x width x num_channels]\n",
    "    #            mp_len: size of max pool window, also the stride for this MP\n",
    "    # \n",
    "    # Returns:   p_out: output of pooling R0. [N x output_height x output_width x num_channels]\n",
    "    #            R0_mask: A binary mask with the same size as R0. Indicates which index was chosen to be the max\n",
    "    #            for each max pool window. This will be used for backpropagation.\n",
    "\n",
    "def maxPool(R0, mp_len):\n",
    "\n",
    "    N, R0_len, _, num_ch = R0.shape\n",
    "    p_out_len = int((R0_len-mp_len)/mp_len + 1)\n",
    "\n",
    "    R0_mask = np.zeros(R0.shape)\n",
    "    p_out = np.zeros((N, p_out_len, p_out_len, num_ch))\n",
    "    \n",
    "    for n in range(N):\n",
    "        for ch in range(num_ch):\n",
    "            for row in range(p_out_len): \n",
    "                for col in range(p_out_len):\n",
    "                    # YOUR CODE HERE\n",
    "\n",
    "\n",
    "    return p_out, R0_mask\n",
    "\n",
    "\n",
    "# fc\n",
    "    # Inputs:    X: [N x num_input_features]\n",
    "    #            W: [num_input_features x num_fc_nodes]\n",
    "    # \n",
    "    # Returns:   out: Linear combination of X and W. [N x num_fc_nodes]\n",
    "\n",
    "def fc(X, W):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_fwd\n",
    "    # Inputs:    X0: batch of images. [N x img_height x img_width x num_channels]\n",
    "    #            W0, W1, W2: Parameters of the CNN\n",
    "    #            mp_len: the length of one side of the max pool window\n",
    "    # \n",
    "    # Returns:   sig: vector containing the output for each sample. [N x 1]\n",
    "    #            cache: a dict containing the relevant output layer calculations that will be\n",
    "    #            used in backpropagation\n",
    "    \n",
    "def cnn_fwd(X0, W0, W1, W2, mp_len):\n",
    "    \n",
    "    # F0 \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # X1p \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # X1 (flatten)\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # FC Layers\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Output\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Save outputs of functions for backward pass\n",
    "    cache = {\n",
    "        \"F0\":F0,\n",
    "        \"R0\":R0,\n",
    "        \"X1p\":X1p,\n",
    "        \"R0m\":R0_mask,\n",
    "        \"X1\":X1,\n",
    "        \"F1\":F1,\n",
    "        \"X2\":X2,\n",
    "        \"F2\":F2      \n",
    "    }\n",
    "    \n",
    "    return sig, cache\n",
    "\n",
    "\n",
    "# loss\n",
    "    # Inputs:    sig: vector containing the CNN output for each sample. [N x 1]\n",
    "    #            Y: vector containing the ground truth label for each sample. [N x 1]\n",
    "    # \n",
    "    # Returns:   L: Loss/error criterion for the model. \n",
    "\n",
    "def loss(sig, Y):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return L\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backprop Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolve2DBwd\n",
    "    # Inputs:    X0: batch of images. [N x height x width x num_channels]\n",
    "    #            dL_dF0: Gradient at the output of the conv layer. \n",
    "    # \n",
    "    # Returns:   dL_dW0. gradient of loss L wrt W0. Same size as W0\n",
    "\n",
    "def convolve2DBwd(X0, dL_dF0):\n",
    "    \n",
    "    N, X0_len, _, num_ch = X0.shape\n",
    "    _, dL_dF0_len, _, num_out_ch  = dL_dF0.shape\n",
    "    filter_len = X0_len - dL_dF0_len + 1\n",
    "    \n",
    "    dL_dW0 = np.zeros((num_out_ch, filter_len, filter_len, num_ch))\n",
    "    \n",
    "    for n in range(N):\n",
    "        for o_ch in range(num_out_ch):\n",
    "            for ch in range(num_ch):\n",
    "                # YOUR CODE HERE \n",
    "    \n",
    "    return dL_dW0\n",
    "\n",
    "\n",
    "# maxPoolBwd\n",
    "    # Inputs:    dL_dX1p: Gradient at the output of the MaxPool layer\n",
    "    #            R0_mask: A binary mask with the same size as R0. Defined in maxPool\n",
    "    #            mp_len: the length of one side of the max pool window\n",
    "    # \n",
    "    # Returns:   dL_dR0: Gradient at the output of ReLu\n",
    "    \n",
    "def maxPoolBwd(dL_dX1p, R0_mask,  mp_len):\n",
    "    \n",
    "    N, H, W, C = R0_mask.shape\n",
    "    N, dH, dW, C = dL_dX1p.shape\n",
    "    \n",
    "    dL_dR0 = np.zeros(R0_mask.shape)\n",
    "    \n",
    "    for n in range(N):\n",
    "        for ch in range(C):\n",
    "            for row in range(dH):\n",
    "                for col in range(dW):\n",
    "                    # YOUR CODE HERE\n",
    "                    \n",
    "    return dL_dR0\n",
    "\n",
    "\n",
    "# dL_dW2\n",
    "    # Inputs:    Y: vector containing the ground truth label for each sample. [N x 1]\n",
    "    #            cache: a dict containing the relevant output layer calculations \n",
    "    # \n",
    "    # Returns:   dL_dW2: Gradient of the Loss wrt W2\n",
    "    \n",
    "def dL_dW2(Y, cache):\n",
    "   \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return dL_dW2\n",
    "\n",
    "\n",
    "# dL_dW1\n",
    "    # Inputs:    Y: vector containing the ground truth label for each sample. [N x 1]\n",
    "    #            W2: Weight matrix for the second FC layer\n",
    "    #            cache: a dict containing the relevant output layer calculations \n",
    "    # \n",
    "    # Returns:   dL_dW1: Gradient of the Loss wrt W1\n",
    "    \n",
    "def dL_dW1(Y, W2, cache):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return dL_dW1\n",
    "\n",
    "\n",
    "# dL_dW0\n",
    "    # Inputs:    X0: batch of images. [N x height x width x num_channels]\n",
    "    #            Y: vector containing the ground truth label for each sample. [N x 1]\n",
    "    #            W1: Weight matrix for the first FC layer\n",
    "    #            W2: Weight matrix for the second FC layer\n",
    "    #            mp_len: the length of one side of the max pool window\n",
    "    #            cache: a dict containing the relevant output layer calculations \n",
    "    # \n",
    "    # Returns:   dL_dW0: Gradient of the Loss wrt W0\n",
    "\n",
    "def dL_dW0(X0, Y, W1, W2, mp_len, cache):\n",
    "    \n",
    "    N, X1p_len, _, no_out_ch  = cache['X1p'].shape\n",
    "    F2 = cache['F2']\n",
    "    F1 = cache['F1']\n",
    "    R0m = cache['R0m']\n",
    "    F0 = cache['F0']\n",
    "    \n",
    "    #dL_dF2\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    #dL_dF1\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    #dL_dX1\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # dL_dX1p (unflatten)\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # dL_dR0 (unpool)\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # dL_dF0 (relu_bwd)\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # dL_dW0\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return dL_dW0\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and scale them\n",
    "# YOUR CODE HERE\n",
    "train_set, val_set = load_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 20\n",
    "lr = 0.1\n",
    "batch_size = 16\n",
    "filter_len = 5\n",
    "num_out_ch = 3\n",
    "mp_len = 12\n",
    "fc_nodes = 2\n",
    "\n",
    "# Declare weights\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epochs):\n",
    "    \n",
    "    # make set of batches\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    for b_idx in range(num_batches):\n",
    "        X = img_batches[b_idx]\n",
    "        Y = label_batches[b_idx]\n",
    "        \n",
    "        # Forward pass\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # Calculate gradients\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # Update gradients\n",
    "        # YOUR CODE HERE\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Correctness of Forward and Backward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.load('weights.npz')\n",
    "W0 = weights['W0']\n",
    "W1 = weights['W1']\n",
    "W2 = weights['W2']\n",
    "\n",
    "sig, _ = cnn_fwd(val_set[0], W0, W1, W2, mp_len)\n",
    "train_acc = len(np.where(np.round(sig) == val_set[1])[0])/len(val_set[1])\n",
    "\n",
    "print(\"train_loss:\", loss(sig, val_set[1]), \"train_acc:\", train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make backprop testing batch\n",
    "X_bp = np.vstack([train_set[0][0:8,:,:,:], train_set[0][-9:-1,:,:,:]])\n",
    "Y_bp = np.vstack([train_set[1][0:8], train_set[1][-9:-1]])\n",
    "\n",
    "# Initialize weights to all ones\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Update weights once\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "print(\"W2 value:\", np.sum(W2))\n",
    "print(\"W1 value:\", np.sum(W1))\n",
    "print(\"W0 value:\", np.sum(W0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
